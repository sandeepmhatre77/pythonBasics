{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Initializing the Spark Context",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepmhatre77/pythonBasics/blob/master/Initializing_the_Spark_Context.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILDb7AGqq_k7"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmRNNGELrz8y"
      },
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYjNZXwrr3u-"
      },
      "source": [
        "!tar xf spark-3.0.1-bin-hadoop3.2.tgz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et1mINcMscOm"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jn8KsmlsvoG",
        "outputId": "3649552f-f442-408c-82b1-380a4342ee63"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
            "\u001b[K     |████████████████████████████████| 204.2MB 66kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 37.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612242 sha256=d3dc7e0794c4a0fa5d29afa618ac1dcdaac733c385348467255b0b1346519ff5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmMKC4VLs2wF"
      },
      "source": [
        "from pyspark import SparkContext, SparkConf\r\n",
        "#sc = SparkContext()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE9XDiAcvcNy"
      },
      "source": [
        "'''sc.getConf().getAll()\r\n",
        "sc.stop()\r\n",
        "'''\r\n",
        "conf = SparkConf().setAppName(\"TestApp\").setMaster(\"local\")\r\n",
        "sc = SparkContext(conf = conf)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AywPIDgzKrZZ",
        "outputId": "30498919-84e5-48c1-c26e-06dd2ff3e671"
      },
      "source": [
        "sc.getConf().getAll()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('spark.master', 'local'),\n",
              " ('spark.driver.port', '43315'),\n",
              " ('spark.rdd.compress', 'True'),\n",
              " ('spark.app.id', 'local-1610127980492'),\n",
              " ('spark.serializer.objectStreamReset', '100'),\n",
              " ('spark.app.name', 'TestApp'),\n",
              " ('spark.submit.pyFiles', ''),\n",
              " ('spark.executor.id', 'driver'),\n",
              " ('spark.submit.deployMode', 'client'),\n",
              " ('spark.driver.host', 'c729aeb10478'),\n",
              " ('spark.ui.showConsoleProgress', 'true')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBsCdHr3K0ia"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_gc93jUK6hR"
      },
      "source": [
        "Another Way to initialize the spark context is shown as below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d95nxAHIK4za"
      },
      "source": [
        "sc = SparkContext()\r\n",
        "#sc.stop()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5xZduHlLQxb",
        "outputId": "28eec67a-a6fd-4e1c-c67a-e420299bbb73"
      },
      "source": [
        "sc.getConf().getAll()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('spark.master', 'local'),\n",
              " ('spark.driver.port', '45079'),\n",
              " ('spark.app.id', 'local-1610127981892'),\n",
              " ('spark.rdd.compress', 'True'),\n",
              " ('spark.serializer.objectStreamReset', '100'),\n",
              " ('spark.app.name', 'TestApp'),\n",
              " ('spark.submit.pyFiles', ''),\n",
              " ('spark.executor.id', 'driver'),\n",
              " ('spark.submit.deployMode', 'client'),\n",
              " ('spark.driver.host', 'c729aeb10478'),\n",
              " ('spark.ui.showConsoleProgress', 'true')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISux7P1dLKG8"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv3y2GrRvEHo"
      },
      "source": [
        "sc= SparkContext(\"local\", \"first App\")\r\n",
        "\r\n",
        "a = sc.parallelize([1,34,5,543])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej8oQKONL1j0",
        "outputId": "05cc6943-342d-4f39-983d-5c6949bcb4a9"
      },
      "source": [
        "sc.getConf().getAll()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('spark.master', 'local'),\n",
              " ('spark.driver.port', '39457'),\n",
              " ('spark.rdd.compress', 'True'),\n",
              " ('spark.app.id', 'local-1610127982655'),\n",
              " ('spark.serializer.objectStreamReset', '100'),\n",
              " ('spark.submit.pyFiles', ''),\n",
              " ('spark.executor.id', 'driver'),\n",
              " ('spark.submit.deployMode', 'client'),\n",
              " ('spark.driver.host', 'c729aeb10478'),\n",
              " ('spark.app.name', 'first App'),\n",
              " ('spark.ui.showConsoleProgress', 'true')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YSWsYYuKp3B",
        "outputId": "72fe3d1a-e4cc-4340-f836-c8ea8f935149"
      },
      "source": [
        "a # used parallelize so that data can be distributed among the cores / cluster / nodes "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:262"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6cvyfvEveLP"
      },
      "source": [
        "a1 = a.collect() # we should not use collect in pyspark instead use take(5) \r\n",
        "# it will collect all the data in the ram and our system may get collapse"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0A2n-Ydvi0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68160a7b-1382-4afd-bd2b-649c98223c97"
      },
      "source": [
        "a.countByValue()\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int, {1: 1, 5: 1, 34: 1, 543: 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soOlIboKvfw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95fbce9f-f642-4121-93cd-fd804e8df949"
      },
      "source": [
        "a.take(2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 34]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVGtmkNvvVC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64b5ab6-421f-4bbf-808f-da518e4aff9e"
      },
      "source": [
        "\r\n",
        "a.collect()\r\n",
        "\r\n",
        "\r\n",
        "a.take(3)\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 34, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E6YcrWHHPhl"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7keLWzBPTfY"
      },
      "source": [
        "sc= SparkContext(\"local\", \"first App\")\r\n",
        "\r\n",
        "df = sc.parallelize([(1, 2, 3, 'a b c'),(4, 5, 6, 'd e f'),(7, 8, 9, 'g h i')])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMDRyAv4PGsc",
        "outputId": "6cc5646c-c3e4-48e1-f8cf-2df1611fcb9e"
      },
      "source": [
        "df.collect()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 2, 3, 'a b c'), (4, 5, 6, 'd e f'), (7, 8, 9, 'g h i')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wxA7MdMPNqh"
      },
      "source": [
        "#/content/sample_data/california_housing_test.csv\r\n",
        "\r\n",
        "sc.stop()\r\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZXGThaLUTya"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Python Spark create RDD example\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljsQ-YwxVaYl"
      },
      "source": [
        "df = spark.read.format('com.databricks.spark.csv').options(header='true',inferschema='true').load(\"/content/sample_data/california_housing_test.csv\", header=True)\r\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoGdV3eYViH4",
        "outputId": "4826113d-560b-492a-b528-b4c4b8ffe40e"
      },
      "source": [
        "df.show(5)\r\n",
        "df.printSchema()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -122.05|   37.37|              27.0|     3885.0|         661.0|    1537.0|     606.0|       6.6085|          344700.0|\n",
            "|   -118.3|   34.26|              43.0|     1510.0|         310.0|     809.0|     277.0|        3.599|          176500.0|\n",
            "|  -117.81|   33.78|              27.0|     3589.0|         507.0|    1484.0|     495.0|       5.7934|          270500.0|\n",
            "|  -118.36|   33.82|              28.0|       67.0|          15.0|      49.0|      11.0|       6.1359|          330000.0|\n",
            "|  -119.67|   36.33|              19.0|     1241.0|         244.0|     850.0|     237.0|       2.9375|           81700.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2BG1-hfVzLH"
      },
      "source": [
        "roomgroup = df.groupby('total_rooms')\r\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWsq3WTeVmiE",
        "outputId": "e49bc4fc-f947-44ca-d571-25092449628f"
      },
      "source": [
        "roomgroup.mean('median_income').take(10)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(total_rooms=2734.0, avg(median_income)=2.8085),\n",
              " Row(total_rooms=305.0, avg(median_income)=5.9641),\n",
              " Row(total_rooms=4066.0, avg(median_income)=4.6556),\n",
              " Row(total_rooms=2862.0, avg(median_income)=5.01355),\n",
              " Row(total_rooms=1051.0, avg(median_income)=3.9246999999999996),\n",
              " Row(total_rooms=769.0, avg(median_income)=1.7875),\n",
              " Row(total_rooms=1761.0, avg(median_income)=5.399),\n",
              " Row(total_rooms=5776.0, avg(median_income)=6.6447),\n",
              " Row(total_rooms=596.0, avg(median_income)=4.2813),\n",
              " Row(total_rooms=12467.0, avg(median_income)=3.2846)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnKHdpe6WLQ6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}